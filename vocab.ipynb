{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "import json\n",
    "from math import log2\n",
    "from pathlib import Path\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(title):\n",
    "    s = re.sub(r'[^a-zA-Z0-9ñç% ]', ' ', unicodedata.normalize('NFKD', title.lower()).encode('ascii', 'ignore').decode(\"utf-8\"))\n",
    "    s = re.sub(r'[\\d]+', \"1\", s)\n",
    "    s = re.sub(r's |s$', ' ', s)\n",
    "    s = re.sub(r' +', ' ', s)\n",
    "    s = re.sub(r'(1 )+', '1 ', s)\n",
    "    return re.sub(r'o |o$', 'a ', s).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "if not (PATH / 'train_prepro.csv').exists():\n",
    "\tdf = pd.read_csv('train.csv')\n",
    "\tprint(\"1\")\n",
    "\tdf['title'] = df.title.apply(normalize_title)\n",
    "\tprint(\"2\")\n",
    "\tdf = df[~df.title.isna() & (df.title != 'nan') & (df.title != '')]\n",
    "\tdf.to_csv(PATH / 'train_prepro.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_prepro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if not (PATH / 'important.json').exists():\n",
    "\td = defaultdict(Counter)\n",
    "\n",
    "\tdef process(r):\n",
    "\t\tws = r['title'].split(' ')\n",
    "\n",
    "\t\tfor w in ws:\n",
    "\t\t\td[w][r['category']] += 1\n",
    "\n",
    "\tprint(\"a\")\n",
    "\tdf.apply(process, axis=1)\n",
    "\n",
    "\tword_importance = dict()\n",
    "\n",
    "\tfor w, c in d.items():\n",
    "\t\timportance = 0\n",
    "\t\tcount = 0\n",
    "\n",
    "\t\tfor x in c.most_common():\n",
    "\t\t\tif x[1] < 10:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tcount += 1\t\n",
    "\t\t\timportance += x[1]\n",
    "\n",
    "\t\tif count > 0:\t\n",
    "\t\t\tword_importance[w] = min(importance, 100000) / (count**2)\n",
    "\n",
    "\n",
    "\n",
    "\twith open(PATH / 'important.json', \"w\") as f:\n",
    "\t\tjson.dump(word_importance, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"important.json\", \"r\") as f:\n",
    "\tword_importance = json.load(f)\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "QTY = 60000\n",
    "\n",
    "if not (PATH / f'vocab{QTY}.json').exists():\n",
    "\n",
    "\tcats = df['category'].nunique()\n",
    "\ttotal = 60000 - 15 * cats\n",
    "\tcarry = 0\n",
    "\timportant = set()\n",
    "\tordered = []\n",
    "\n",
    "\tfor index, rows in sorted(df.groupby('category'), key=lambda x: len(x[1]), reverse=True):\n",
    "\t\tavailable = 15 + floor(total * len(rows) / len(df)) + carry\n",
    "\t\twords = defaultdict(int)\n",
    "\n",
    "\t\tdef process(r):\n",
    "\t\t\tws = r.split(' ')\n",
    "\t\t\tweights = [word_importance.get(x, 0) for x in ws]\n",
    "\t\t\ttotal = sum(weights)\n",
    "\n",
    "\t\t\tfor w, wei in zip(ws[0:len(ws)//2], weights):\n",
    "\t\t\t\twords[w] += wei / total if total > 0 else 1/len(ws)\n",
    "\n",
    "\t\trows['title'].apply(process)\n",
    "\n",
    "\t\tfor w in sorted(words.keys(), key = lambda x: words[x], reverse=True):\n",
    "\t\t\tif w not in important:\n",
    "\t\t\t\timportant.add(w)\n",
    "\t\t\t\tordered.append(w)\n",
    "\t\t\t\tavailable -= 1\n",
    "\t\t\t\tif available == 0:\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\tcarry = available\n",
    "\n",
    "\n",
    "\tfor w in sorted(word_importance, key=lambda x: word_importance[x], reverse=True):\n",
    "\t\tif w not in important:\n",
    "\t\t\timportant.add(w)\n",
    "\t\t\tordered.append(w)\n",
    "\t\t\tif len(important) == QTY:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\n",
    "\twith open(PATH / f'vocab{QTY}.json', \"w\") as f:\n",
    "\t\tjson.dump(ordered, f)\n",
    "\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH / f'vocab{QTY}.json', \"r\") as f:\n",
    "\tvocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pd.Series(' '.join(df.title).split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(vocab)\n",
    "from symspellpy.symspellpy import SymSpell  # import the module\n",
    "sym_spell = SymSpell(2, 7)\n",
    "for word in vocab:\n",
    "    sym_spell.create_dictionary_entry(word, count[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rusty 1 2403 rasty 9 2403\n",
      "cocoa 1 359 cocopa 9 359\n",
      "electrica 1 117983 electrica1 9 117983\n",
      "bosch 1 62027 bossh 9 62027\n",
      "cachoeira 1 573 cachoeira1 9 573\n",
      "exata 1 314 exalta 9 314\n",
      "intel 2 39685 injetel 9 39685\n",
      "alti 1 238 altit 9 238\n",
      "t1w 1 499 lt1w 9 499\n",
      "kenwood 1 4374 kewood 9 4374\n",
      "leiser 1 35 bleiser 9 35\n",
      "morgan 2 879 mohuan 9 879\n",
      "gira 2 32653 gojira 9 32653\n",
      "tcs1f 1 80 tls1f 9 80\n",
      "perola 1 9436 peroila 9 9436\n",
      "prestan 1 21 prespan 9 21\n",
      "fortune 1 319 fortunei 9 319\n",
      "pms1 1 332 pmks1 9 332\n",
      "kala 1 3135 kayla 9 3135\n",
      "martor 1 58 martyr 9 58\n",
      "usada 2 124667 kusama 9 124667\n",
      "boligrafa 1 6461 boligraf 9 6461\n",
      "microserva 2 15 microserie 9 15\n",
      "fp1 1 1795 wfp1 9 1795\n",
      "neumatica 1 21719 naumatica 9 21719\n",
      "france 1 17382 franch 9 17382\n",
      "aplicador 1 2711 aplicator 9 2711\n",
      "maxiking 2 80 maxilink 9 80\n",
      "dc1d1 1 12 dc1db1 9 12\n",
      "vigueta 1 634 vegueta 9 634\n",
      "expor 2 116 nexpod 9 116\n",
      "arc 1 1680 arxc 9 1680\n",
      "training 1 4789 traiding 9 4789\n",
      "vp1tf 1 76 vk1tf 9 76\n",
      "mascara 2 82735 malacara 9 82735\n",
      "receptore 1 787 1receptore 9 787\n",
      "bnc 1 1618 1bnc 9 1618\n",
      "1un 2 46826 1znu 9 46826\n",
      "weizen 1 137 wizen 9 137\n",
      "uhf1 2 174 uhf1ch 9 174\n",
      "everyday 2 301 everydaily 9 301\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for word, c in count.iteritems():\n",
    "    if word not in vocab and count[word] < 10:\n",
    "        suggestions = sym_spell.lookup(word, 2)\n",
    "        for suggestion in suggestions[0:1]:\n",
    "            if suggestion.distance > 0:\n",
    "                print(suggestion.term, suggestion.distance,\n",
    "                              suggestion.count, word, count[word], count.get(suggestion.term, 0))\n",
    "                a += 1  \n",
    "    if a > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell  # import the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_spell = SymSpell(2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocab:\n",
    "    sym_spell.create_dictionary_entry(word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidrolavadora lavor one 1 bar 1w bomba aluminia itala, 1, 1, hidrolavadora lavor one 1 bar 1w bomba aluminia italia\n",
      "kit tripe para celular ou camera motog 1 1m brinde nf e, 1, 1, kit tripe para celular ou camera fotog 1 1m brinde nf e\n",
      "filtra ar bon anza 1 star1, 2, 1, filtra ar bonanza 1 sar1\n",
      "condensador bosch vw fusca 1 1 de 1 a 1, 1, 1, condensador bosch vw fusca 1.1 de 1 a 1\n",
      "rosaria contador de billete uv 1mg detecta falsa nueva, 1, 1, rosaria contador de billete uv mg detecta falsa nueva\n",
      "caixa setor hidraulica ford focu 1 1 1, 1, 1, caixa setor hidraulica ford focu 1.1 1\n",
      "porton de chapa 1 hoja mtr 1 1 sin marca, 1, 1, porton de chapa 1 hoja mtr 1.1 sin marca\n",
      "vauen oxford 1 tabacca pipe cachimba madeira, 1, 1, vauen oxford 1 tobacca pipe cachimba madeira\n",
      "faixa auta colante core surtida 1cm, 2, 1, faixa auta colante core sortida 1cm.\n",
      "maquina para sublimar estampar moldex 1x1, 1, 1, maquina para sublimar estampar goldex 1x1\n",
      "disfraz de general g levou para adulta toalla unica, 3, 1, disfraz de general grievou para adulta talla unica\n",
      "cilindra roda traseira amarok 1 cf1, 2, 1, cilindra roda traseira amarok 1.. cf1\n",
      "schwarzkopf fibre force mascarilla forti picante, 2, 1, schwarzkopf fibre force mascarilla fortificante\n",
      "cuadra decorativa moderna arte 1x1 lamina kombat n1, 1, 1, cuadra decorativa moderna arte 1x1 lamina wombat n1\n",
      "set de lata mate modela galicia oliverta gamma deca, 2, 1, set de lata mate modela alicia oliverta gemma deca\n",
      "camiseta raglan cr muscula palou baby look, 4, 1, camiseta raglan crepuscula jealou baby look\n",
      "se vende galaxy tab1 1 1 wi fi, 1, 1, se vende galaxy tab1 1.1 wi fi\n",
      "camera canon sx 1h wifi nfc consulta fispa habilidade, 6, 1, camera canon sx 1h wifi nfc consulte disponibilidade\n",
      "apc 1litra ternnova limpiador multiproposita tapizada y motor, 1, 1, apc 1litr ternnova limpiador multiproposita tapizada y motor\n",
      "formula nan 1 optipra para mayorea de 1 ana de 1g, 1, 1, formula nan 1 optipra para mayore de 1 ana de 1g\n",
      "inflador 1 vol con 1 adaptadore, 1, 1, inflador 1 vol. con 1 adaptadore\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for index, row in df.iterrows():\n",
    "    suggestions = sym_spell.lookup_compound(row['title'],  2)\n",
    "    for suggestion in suggestions[0:1]:\n",
    "        if suggestion.distance > 0:\n",
    "            print(\"{}, {}, {}, {}\".format(suggestion.term, suggestion.distance,\n",
    "                              suggestion.count, row['title']))\n",
    "            a += 1\n",
    "    if a > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SymSpell.lookup_compound??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1677"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index('vol.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
